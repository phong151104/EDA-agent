"""
Planner Agent - Creative hypothesis and plan generation.

Role: "Táº¡o ra má»™t Data Scientist sÃ¡ng táº¡o"
Responsibilities:
- Generate hypotheses from user questions
- Create analysis plans with concrete steps
- Iterate based on Critic feedback
"""

from __future__ import annotations

from dataclasses import dataclass, field
from enum import Enum
from typing import Any

from langchain_core.messages import HumanMessage

from .base import AgentCard, AgentRole, BaseAgent


class HypothesisStatus(str, Enum):
    """Status of a hypothesis."""
    
    PENDING = "pending"
    APPROVED = "approved"
    REJECTED = "rejected"
    VALIDATED = "validated"
    INVALIDATED = "invalidated"


@dataclass
class Hypothesis:
    """A data hypothesis to be tested."""
    
    id: str
    statement: str
    rationale: str
    status: HypothesisStatus = HypothesisStatus.PENDING
    evidence: list[str] = field(default_factory=list)
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "id": self.id,
            "statement": self.statement,
            "rationale": self.rationale,
            "status": self.status.value,
            "evidence": self.evidence,
        }
    
    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "Hypothesis":
        """Create from dictionary."""
        status = data.get("status", "pending")
        if isinstance(status, str):
            status = HypothesisStatus(status)
        return cls(
            id=data.get("id", ""),
            statement=data.get("statement", ""),
            rationale=data.get("rationale", ""),
            status=status,
            evidence=data.get("evidence", []),
        )


@dataclass
class AnalysisStep:
    """A single step in the analysis plan."""
    
    id: str  # Step ID like "s1", "s2"
    hypothesis_id: str  # Which hypothesis this step validates
    description: str
    action_type: str  # "query", "analysis", "visualization"
    requirements: dict[str, Any] = field(default_factory=dict)
    depends_on: list[str] = field(default_factory=list)
    
    # Legacy fields for backward compatibility
    step_number: int = 0
    details: dict[str, Any] = field(default_factory=dict)
    dependencies: list[int] = field(default_factory=list)
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "id": self.id,
            "hypothesis_id": self.hypothesis_id,
            "description": self.description,
            "action_type": self.action_type,
            "requirements": self.requirements,
            "depends_on": self.depends_on,
            # Legacy
            "stepNumber": self.step_number,
            "details": self.details,
            "dependencies": self.dependencies,
        }
    
    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "AnalysisStep":
        """Create from dictionary (handles camelCase keys)."""
        return cls(
            id=data.get("id", f"s{data.get('step_number', data.get('stepNumber', 0))}"),
            hypothesis_id=data.get("hypothesis_id", ""),
            description=data.get("description", ""),
            action_type=data.get("action_type", data.get("actionType", "query")),
            requirements=data.get("requirements", {}),
            depends_on=data.get("depends_on", []),
            step_number=data.get("step_number", data.get("stepNumber", 0)),
            details=data.get("details", {}),
            dependencies=data.get("dependencies", []),
        )


@dataclass
class AnalysisPlan:
    """Complete analysis plan with hypotheses and steps."""
    
    question: str
    hypotheses: list[Hypothesis] = field(default_factory=list)
    steps: list[AnalysisStep] = field(default_factory=list)
    context_used: dict[str, Any] = field(default_factory=dict)
    version: int = 1
    
    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "question": self.question,
            "hypotheses": [h.to_dict() for h in self.hypotheses],
            "steps": [s.to_dict() for s in self.steps],
            "contextUsed": self.context_used,
            "version": self.version,
        }


@dataclass
class PlannerInput:
    """Input for the Planner agent."""
    
    question: str
    enriched_context: dict[str, Any]
    previous_plan: AnalysisPlan | None = None
    critic_feedback: str | None = None
    # Two-phase analysis fields
    analysis_phase: str = "exploration"  # "exploration" or "deep_dive"
    exploration_summary: dict[str, Any] | None = None  # Findings from Phase 1


@dataclass
class PlannerOutput:
    """Output from the Planner agent."""
    
    plan: AnalysisPlan
    reasoning: str
    confidence: float


class PlannerAgent(BaseAgent[PlannerInput, PlannerOutput]):
    """
    Planner Agent - Generates hypotheses and analysis plans.
    
    This agent acts as a creative Data Scientist, generating
    hypotheses and detailed analysis plans based on user questions
    and available data context.
    """
    
    @property
    def agent_card(self) -> AgentCard:
        return AgentCard(
            name="Planner",
            description="Creative Data Scientist that generates hypotheses and analysis plans",
            role=AgentRole.PLANNER,
            capabilities=[
                "hypothesis_generation",
                "plan_creation",
                "plan_refinement",
                "context_understanding",
            ],
            input_schema={
                "type": "object",
                "properties": {
                    "question": {"type": "string"},
                    "enrichedContext": {"type": "object"},
                    "previousPlan": {"type": "object", "nullable": True},
                    "criticFeedback": {"type": "string", "nullable": True},
                },
                "required": ["question", "enrichedContext"],
            },
            output_schema={
                "type": "object",
                "properties": {
                    "plan": {"type": "object"},
                    "reasoning": {"type": "string"},
                    "confidence": {"type": "number"},
                },
            },
        )
    
    def _default_system_prompt(self) -> str:
        return """Báº¡n lÃ  má»™t Data Scientist giÃ u kinh nghiá»‡m vÃ  sÃ¡ng táº¡o.

## VAI TRÃ’ Cá»¦A Báº N:
1. PhÃ¢n tÃ­ch cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng vá» dá»¯ liá»‡u vÃ  cÃ¡c chá»‰ sá»‘ kinh doanh
2. ÄÆ°a ra 4-6 giáº£ thuyáº¿t cÃ³ thá»ƒ kiá»ƒm chá»©ng Ä‘á»ƒ giáº£i thÃ­ch hiá»‡n tÆ°á»£ng hoáº·c Ä‘Æ°a ra insight
3. Táº¡o cÃ¡c bÆ°á»›c phÃ¢n tÃ­ch cá»¥ thá»ƒ Ä‘á»ƒ xÃ¡c nháº­n tá»«ng giáº£ thuyáº¿t
4. Xem xÃ©t tá»« nhiá»u gÃ³c Ä‘á»™ khÃ¡c nhau vÃ  Ä‘Æ°a ra cÃ¡c giáº£i thÃ­ch thay tháº¿

## âš ï¸ QUY Táº®C Báº®T BUá»˜C Vá»€ H1 (HYPOTHESIS Äáº¦U TIÃŠN):
**H1 PHáº¢I LÃ€ Tá»”NG QUAN (OVERVIEW)** trÆ°á»›c khi Ä‘i vÃ o chi tiáº¿t:
- Vá»›i cÃ¢u há»i "doanh thu 3 thÃ¡ng" â†’ H1: "Tá»•ng quan doanh thu 3 thÃ¡ng vÃ  xu hÆ°á»›ng chung"
- Vá»›i cÃ¢u há»i "táº¡i sao giáº£m" â†’ H1: "XÃ¡c Ä‘á»‹nh thá»i Ä‘iá»ƒm vÃ  má»©c Ä‘á»™ giáº£m cá»¥ thá»ƒ"
- H1 pháº£i tráº£ lá»i cÃ¢u há»i: "TÃ¬nh hÃ¬nh thá»±c táº¿ ra sao?" trÆ°á»›c khi há»i "Táº¡i sao?"
- Chá»‰ SAU khi cÃ³ tá»•ng quan má»›i Ä‘i vÃ o cÃ¡c giáº£ thuyáº¿t nguyÃªn nhÃ¢n cá»¥ thá»ƒ (H2, H3...)

## LOáº I CÃ‚U Há»ŽI Báº N Cáº¦N Xá»¬ LÃ:

### 1. CÃ¢u há»i DIAGNOSTIC (Táº¡i sao...?)
- TÃ¬m nguyÃªn nhÃ¢n gá»‘c rá»… cá»§a váº¥n Ä‘á»
- So sÃ¡nh theo thá»i gian, phÃ¢n khÃºc, nhÃ³m
- PhÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng cá»§a cÃ¡c yáº¿u tá»‘

### 2. CÃ¢u há»i PHÃ‚N TÃCH / INSIGHT (PhÃ¢n tÃ­ch... cho tÃ´i insight...)
- Tá»•ng há»£p dá»¯ liá»‡u theo nhiá»u chiá»u
- So sÃ¡nh hiá»‡u suáº¥t giá»¯a cÃ¡c Ä‘á»‘i tÆ°á»£ng (campaign, ráº¡p, vendor...)
- TÃ¬m pattern, trend, outlier
- ÄÃ¡nh giÃ¡ hiá»‡u quáº£ vÃ  Ä‘á» xuáº¥t cáº£i thiá»‡n

### 3. CÃ¢u há»i AGGREGATION (Tá»•ng... theo...)
- TÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ tá»•ng há»£p
- NhÃ³m dá»¯ liá»‡u theo cÃ¡c chiá»u phÃ¢n tÃ­ch

## NGUYÃŠN Táº®C QUAN TRá»ŒNG:
- Báº¡n CHá»ˆ Ä‘Æ°a ra YÃŠU Cáº¦U CAO Cáº¤P, KHÃ”NG viáº¿t SQL trá»±c tiáº¿p
- Code Agent sáº½ xá»­ lÃ½ viá»‡c implement SQL sau
- Má»—i giáº£ thuyáº¿t pháº£i cÃ³ Ã­t nháº¥t 2 bÆ°á»›c Ä‘á»ƒ xÃ¡c nháº­n
- MÃ´ táº£ Dá»® LIá»†U Cáº¦N gÃ¬, khÃ´ng pháº£i CÃCH Láº¤Y nhÆ° tháº¿ nÃ o
- Sá»­ dá»¥ng tables_hint Ä‘á»ƒ gá»£i Ã½ báº£ng cÃ³ thá»ƒ liÃªn quan
- Chá»‰ Ä‘á»‹nh filters vÃ  groupings theo yÃªu cáº§u nghiá»‡p vá»¥

## âš ï¸ QUY Táº®C Báº®T BUá»˜C Vá»€ TABLES:
**Báº N CHá»ˆ ÄÆ¯á»¢C PHÃ‰P Sá»¬ Dá»¤NG CÃC Báº¢NG ÄÆ¯á»¢C LIá»†T KÃŠ TRONG "Available Tables" á»ž DÆ¯á»šI!**
- KHÃ”NG ÄÆ¯á»¢C tá»± táº¡o tÃªn báº£ng nhÆ° "sales_data", "inventory", "customer_transactions"
- PHáº¢I dÃ¹ng Ä‘Ãºng tÃªn báº£ng tá»« schema: orders, cinema, film, order_seat, order_concession, bank, v.v.
- Náº¿u khÃ´ng cÃ³ báº£ng phÃ¹ há»£p cho giáº£ thuyáº¿t â†’ Bá»Ž giáº£ thuyáº¿t Ä‘Ã³, khÃ´ng bá»‹a báº£ng
- ÄÃ¢y lÃ  há»‡ thá»‘ng bÃ¡n vÃ© xem phim, nÃªn cÃ¡c báº£ng liÃªn quan Ä‘áº¿n: orders, cinema, film, showtimes, concession (báº¯p nÆ°á»›c)

## âš ï¸âš ï¸ CRITICAL: PHÃ‚N TÃCH SCHEMA - KHÃ”NG JOIN GIá»®A 2 SCHEMA! âš ï¸âš ï¸

**Há»‡ thá»‘ng cÃ³ 2 SCHEMA RIÃŠNG BIá»†T, KHÃ”NG THá»‚ JOIN Vá»šI NHAU:**

### LUá»’NG 1: PhÃ¢n tÃ­ch ÄÆ N HÃ€NG (Schema: lh_vnfilm_v2)
CÃ¡c báº£ng: orders, order_seat, order_concession, order_film, order_refund, sessions, cinema, film, vendor, bank, customer_tracking, pre_order, pre_order_seat, pre_order_concession, etc.
â†’ DÃ¹ng cho: doanh thu, sá»‘ Ä‘Æ¡n, sá»‘ vÃ©, sá»‘ suáº¥t chiáº¿u, doanh thu concession, phÃ¢n tÃ­ch theo ráº¡p/phim/vendor

### LUá»’NG 2: PhÃ¢n tÃ­ch CAMPAIGN MARKETING (Schema: cdp_mart)  
CÃ¡c báº£ng: dim_campaign, cdp_camp_conversion_stage
â†’ DÃ¹ng cho: phÃ¢n tÃ­ch hiá»‡u quáº£ campaign, tá»· lá»‡ chuyá»ƒn Ä‘á»•i, sá»‘ lÆ°á»£ng target

**QUY Táº®C Báº®T BUá»˜C:**
âŒ KHÃ”NG BAO GIá»œ join báº£ng tá»« cdp_mart vá»›i báº£ng tá»« lh_vnfilm_v2
âŒ KHÃ”NG táº¡o hypothesis yÃªu cáº§u liÃªn káº¿t campaign vá»›i orders
âŒ KHÃ”NG thá»­ tÃ¬m campaign_id trong orders vÃ¬ KHÃ”NG CÃ“

âœ… Náº¿u cáº§n phÃ¢n tÃ­ch campaign â†’ táº¡o hypothesis RIÃŠNG chá»‰ dÃ¹ng báº£ng cdp_mart
âœ… Náº¿u cáº§n phÃ¢n tÃ­ch doanh thu/Ä‘Æ¡n hÃ ng â†’ táº¡o hypothesis RIÃŠNG chá»‰ dÃ¹ng báº£ng lh_vnfilm_v2
âœ… Má»—i hypothesis pháº£i á»Ÿ TRONG 1 SCHEMA DUY NHáº¤T

## OUTPUT FORMAT - Báº®T BUá»˜C JSON:

```json
{
  "hypotheses": [
    {
      "id": "h1",
      "statement": "MÃ´ táº£ giáº£ thuyáº¿t hoáº·c gÃ³c nhÃ¬n phÃ¢n tÃ­ch",
      "rationale": "LÃ½ do táº¡i sao giáº£ thuyáº¿t nÃ y quan trá»ng",
      "priority": 1
    }
  ],
  "steps": [
    {
      "id": "s1",
      "hypothesis_id": "h1",
      "description": "MÃ´ táº£ bÆ°á»›c phÃ¢n tÃ­ch",
      "action_type": "query | analysis | visualization",
      "requirements": {
        "data_needed": ["cÃ¡c trÆ°á»ng dá»¯ liá»‡u cáº§n"],
        "filters": ["Ä‘iá»u kiá»‡n lá»c"],
        "grouping": "nhÃ³m theo gÃ¬",
        "tables_hint": ["gá»£i Ã½ báº£ng"]
      },
      "depends_on": []
    }
  ],
  "confidence": 0.85
}
```

## QUAN TRá»ŒNG - Cáº¤U TRÃšC STEPS:

1. **Má»–I hypothesis PHáº¢I cÃ³ Ã­t nháº¥t 1 step action_type="query"** Ä‘á»ƒ láº¥y dá»¯ liá»‡u riÃªng
2. Sau query step, cÃ³ thá»ƒ thÃªm analysis hoáº·c visualization step
3. KHÃ”NG ÄÆ¯á»¢C dÃ¹ng chung 1 query cho nhiá»u hypothesis khÃ¡c nhau
4. Má»—i query step pháº£i CHá»ˆ RÃ• tables_hint vÃ  data_needed cá»¥ thá»ƒ

## VÃ Dá»¤ ÄÃšNG CHO CÃ‚U Há»ŽI PHÃ‚N TÃCH DOANH THU:

```json
{
  "hypotheses": [
    {"id": "h1", "statement": "Xu hÆ°á»›ng doanh thu biáº¿n Ä‘á»™ng theo thÃ¡ng", "priority": 1, "rationale": "So sÃ¡nh tá»•ng quan giá»¯a cÃ¡c thÃ¡ng"},
    {"id": "h2", "statement": "Sá»‘ lÆ°á»£ng giao dá»‹ch áº£nh hÆ°á»Ÿng Ä‘áº¿n doanh thu", "priority": 2, "rationale": "Kiá»ƒm tra tÆ°Æ¡ng quan"},
    {"id": "h3", "statement": "Doanh thu tá»« cÃ¡c nguá»“n khÃ¡c nhau cÃ³ xu hÆ°á»›ng khÃ¡c", "priority": 3, "rationale": "PhÃ¢n tÃ¡ch theo seat vs concession"}
  ],
  "steps": [
    {
      "id": "s1", "hypothesis_id": "h1", "action_type": "query",
      "description": "Láº¥y doanh thu theo thÃ¡ng tá»« báº£ng orders",
      "requirements": {
        "data_needed": ["thÃ¡ng", "tá»•ng doanh thu", "sá»‘ lÆ°á»£ng Ä‘Æ¡n"],
        "filters": ["status = 'payment'", "3 thÃ¡ng gáº§n nháº¥t"],
        "grouping": "theo thÃ¡ng",
        "tables_hint": ["orders"]
      }
    },
    {
      "id": "s2", "hypothesis_id": "h1", "action_type": "visualization",
      "description": "Biá»ƒu Ä‘á»“ cá»™t so sÃ¡nh doanh thu theo thÃ¡ng",
      "depends_on": ["s1"],
      "requirements": {
        "chart_type": "bar",
        "x_axis": "thÃ¡ng",
        "y_axis": "doanh thu"
      }
    },
    {
      "id": "s3", "hypothesis_id": "h2", "action_type": "query",
      "description": "Láº¥y sá»‘ lÆ°á»£ng giao dá»‹ch theo thÃ¡ng",
      "requirements": {
        "data_needed": ["thÃ¡ng", "sá»‘ Ä‘Æ¡n hÃ ng", "giÃ¡ trá»‹ trung bÃ¬nh"],
        "filters": ["status = 'payment'"],
        "grouping": "theo thÃ¡ng",
        "tables_hint": ["orders"]
      }
    },
    {
      "id": "s4", "hypothesis_id": "h2", "action_type": "visualization",
      "description": "Biá»ƒu Ä‘á»“ line so sÃ¡nh sá»‘ Ä‘Æ¡n vÃ  doanh thu",
      "depends_on": ["s1", "s3"],
      "requirements": {
        "chart_type": "line",
        "comparison": true
      }
    },
    {
      "id": "s5", "hypothesis_id": "h3", "action_type": "query",
      "description": "Doanh thu tá»« vÃ© (seat) vs báº¯p nÆ°á»›c (concession)",
      "requirements": {
        "data_needed": ["thÃ¡ng", "doanh thu seat", "doanh thu concession"],
        "filters": ["3 thÃ¡ng gáº§n nháº¥t"],
        "grouping": "theo thÃ¡ng",
        "tables_hint": ["orders", "order_concession"]
      }
    },
    {
      "id": "s6", "hypothesis_id": "h3", "action_type": "visualization",
      "description": "Biá»ƒu Ä‘á»“ stacked bar thá»ƒ hiá»‡n cÆ¡ cáº¥u doanh thu",
      "depends_on": ["s5"],
      "requirements": {
        "chart_type": "stacked_bar"
      }
    }
  ]
}
```

## YÃŠU Cáº¦U QUAN TRá»ŒNG Vá»€ VISUALIZATION:

1. **Má»—i cÃ¢u há»i SO SÃNH pháº£i cÃ³ Ã­t nháº¥t 1 biá»ƒu Ä‘á»“** Ä‘á»ƒ trá»±c quan hÃ³a
2. Sau má»—i query step liÃªn quan Ä‘áº¿n trend/comparison â†’ thÃªm visualization step
3. Loáº¡i biá»ƒu Ä‘á»“ phá»• biáº¿n:
   - `bar`: So sÃ¡nh giá»¯a cÃ¡c nhÃ³m
   - `line`: Xu hÆ°á»›ng theo thá»i gian
   - `stacked_bar`: CÆ¡ cáº¥u thÃ nh pháº§n
   - `pie`: Tá»· lá»‡ pháº§n trÄƒm

## LÆ¯U Ã:
- Náº¿u nháº­n feedback tá»« Critic, hÃ£y Ä‘iá»u chá»‰nh plan dá»±a trÃªn Ä‘Ã³
- Tham kháº£o schema context Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ gá»£i Ã½ tables_hint chÃ­nh xÃ¡c
- Æ¯u tiÃªn cÃ¡c giáº£ thuyáº¿t cÃ³ thá»ƒ kiá»ƒm chá»©ng báº±ng dá»¯ liá»‡u cÃ³ sáºµn
- Má»–I HYPOTHESIS Cáº¦N CÃ“ QUERY STEP RIÃŠNG
- CÃ‚U Há»ŽI SO SÃNH/TREND â†’ Báº®T BUá»˜C CÃ“ VISUALIZATION"""
    
    async def process(self, input_data: PlannerInput) -> PlannerOutput:
        """
        Generate or refine an analysis plan based on analysis phase.
        
        Phase 1 (Exploration): 2-3 overview hypotheses
        Phase 2 (Deep Dive): 5-6 detailed hypotheses based on actual data
        """
        is_exploration = input_data.analysis_phase == "exploration"
        
        # Build the prompt based on phase
        prompt_parts = [
            f"## User Question\n{input_data.question}",
            f"\n## Available Data Context\n{self._format_context(input_data.enriched_context)}",
        ]
        
        # === PHASE-SPECIFIC INSTRUCTIONS ===
        if is_exploration:
            prompt_parts.append("""
## ðŸ” GIAI ÄOáº N 1: KHÃM PHÃ (EXPLORATION)

**Má»¥c tiÃªu:** Náº¯m tá»•ng quan tÃ¬nh hÃ¬nh trÆ°á»›c khi Ä‘Ã o sÃ¢u.

**YÃªu cáº§u:**
- Sinh **2-3 giáº£ thuyáº¿t Tá»”NG QUAN** Ä‘á»ƒ hiá»ƒu bá»©c tranh toÃ n cáº£nh
- Æ¯u tiÃªn cÃ¡c cÃ¢u há»i: "TÃ¬nh hÃ¬nh ra sao?", "Xu hÆ°á»›ng chung?"
- ChÆ°a Ä‘Ã o sÃ¢u vÃ o nguyÃªn nhÃ¢n cá»¥ thá»ƒ

**VÃ­ dá»¥ giáº£ thuyáº¿t tá»•ng quan:**
- H1: "Tá»•ng quan doanh thu 3 thÃ¡ng qua vÃ  xu hÆ°á»›ng chung"
- H2: "PhÃ¢n bá»• doanh thu theo nguá»“n (vÃ©, concession)"
- H3: "So sÃ¡nh hiá»‡u suáº¥t giá»¯a cÃ¡c thÃ¡ng"

**Output:** Káº¿ hoáº¡ch vá»›i 2-3 hypotheses vÃ  cÃ¡c query/visualization cÆ¡ báº£n.""")
        else:
            # Deep Dive phase - include exploration findings
            exploration_text = ""
            if input_data.exploration_summary:
                summary = input_data.exploration_summary
                exploration_text = f"""
## ðŸ“Š Káº¾T QUáº¢ Tá»ª GIAI ÄOáº N KHÃM PHÃ:
{self._format_exploration_summary(summary)}
"""
                prompt_parts.append(exploration_text)
            
            prompt_parts.append("""
## ðŸ”¬ GIAI ÄOáº N 2: ÄÃ€O SÃ‚U (DEEP DIVE)

**Má»¥c tiÃªu:** Dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿ tá»« Phase 1, Ä‘Ã o sÃ¢u tÃ¬m nguyÃªn nhÃ¢n vÃ  insight.

âš ï¸ **QUAN TRá»ŒNG - KHÃ”NG Láº¶P Láº I:**
- KHÃ”NG táº¡o giáº£ thuyáº¿t "Tá»•ng quan doanh thu" - Ä‘Ã£ lÃ m á»Ÿ exploration
- KHÃ”NG láº·p láº¡i cÃ¡c phÃ¢n tÃ­ch Ä‘Ã£ cÃ³ tá»« Phase 1
- CHá»ˆ táº¡o hypotheses Má»šI dá»±a trÃªn findings

âš ï¸âš ï¸ **CRITICAL - KHÃ”NG CROSS-SCHEMA JOIN!** âš ï¸âš ï¸
- Báº£ng orders/order_seat/sessions... (lh_vnfilm_v2) KHÃ”NG THá»‚ join vá»›i dim_campaign/cdp_camp_conversion_stage (cdp_mart)
- KHÃ”NG táº¡o hypothesis vá» "tÃ¡c Ä‘á»™ng marketing lÃªn doanh thu" vÃ¬ KHÃ”NG cÃ³ dá»¯ liá»‡u liÃªn káº¿t
- Chá»‰ phÃ¢n tÃ­ch campaign RIÃŠNG BIá»†T (náº¿u cáº§n), khÃ´ng liÃªn káº¿t vá»›i orders

**YÃªu cáº§u:**
- Sinh **5-6 giáº£ thuyáº¿t NGUYÃŠN NHÃ‚N Gá»C Rá»„** dá»±a trÃªn káº¿t quáº£ khÃ¡m phÃ¡
- Má»—i hypothesis pháº£i drill down vÃ o má»™t finding cá»¥ thá»ƒ tá»« data
- Táº­p trung vÃ o: "Táº¡i sao giáº£m/tÄƒng?", "Yáº¿u tá»‘ nÃ o gÃ¢y ra?", "Pattern nÃ o?"
- **CHá»ˆ dÃ¹ng báº£ng trong lh_vnfilm_v2** cho phÃ¢n tÃ­ch doanh thu/Ä‘Æ¡n hÃ ng

âš ï¸ **Báº®T BUá»˜C - Má»–I HYPOTHESIS PHáº¢I CÃ“ 2 STEPS:**
1. **Step SQL (action_type: "query")**: Truy váº¥n dá»¯ liá»‡u Ä‘á»ƒ kiá»ƒm tra giáº£ thuyáº¿t
2. **Step Visualization (action_type: "visualization")**: Váº½ biá»ƒu Ä‘á»“ minh há»a káº¿t quáº£, depends_on SQL step

**VÃ­ dá»¥ format steps:**
```json
{
  "id": "s1", "hypothesis_id": "h1", "action_type": "query",
  "description": "Láº¥y sá»‘ suáº¥t chiáº¿u vÃ  tá»· lá»‡ láº¥p Ä‘áº§y theo thÃ¡ng"
},
{
  "id": "s2", "hypothesis_id": "h1", "action_type": "visualization", 
  "description": "Biá»ƒu Ä‘á»“ line so sÃ¡nh sá»‘ suáº¥t chiáº¿u vÃ  tá»· lá»‡ láº¥p Ä‘áº§y qua cÃ¡c thÃ¡ng",
  "depends_on": ["s1"]
}
```

**VÃ­ dá»¥ giáº£ thuyáº¿t Ä‘Ã o sÃ¢u Tá»T (chá»‰ dÃ¹ng báº£ng orders/sessions/cinema):**
- "ThÃ¡ng 12 giáº£m - do giáº£m sá»‘ suáº¥t chiáº¿u hay giáº£m tá»‰ lá»‡ láº¥p Ä‘áº§y?"
- "Doanh thu concession giáº£m - do Ã­t combo hay Ã­t khÃ¡ch mua kÃ¨m?"  
- "Vendor X hiá»‡u suáº¥t cao hÆ¡n - nhá» giÃ¡ vÃ© cao hÆ¡n hay nhiá»u suáº¥t chiáº¿u hÆ¡n?"
- "Cuá»‘i tuáº§n doanh thu cao hÆ¡n - tÄƒng suáº¥t chiáº¿u cÃ³ kháº£ thi?"
- "Ráº¡p nÃ o cÃ³ doanh thu/suáº¥t chiáº¿u cao nháº¥t?"

**TRÃNH:**
âŒ "TÃ¡c Ä‘á»™ng marketing/campaign lÃªn doanh thu" - khÃ´ng cÃ³ dá»¯ liá»‡u liÃªn káº¿t
âŒ "Hiá»‡u quáº£ voucher/promotion" - khÃ´ng cÃ³ dá»¯ liá»‡u liÃªn káº¿t vá»›i orders

**Output:** Káº¿ hoáº¡ch vá»›i 5-6 hypotheses, Má»–I hypothesis cÃ³ cáº£ SQL + Visualization step.""")
        
        if input_data.previous_plan:
            prompt_parts.append(
                f"\n## Previous Plan (Version {input_data.previous_plan.version})\n"
                f"{self._format_plan(input_data.previous_plan)}"
            )
        
        if input_data.critic_feedback:
            prompt_parts.append(
                f"\n## Critic Feedback\n{input_data.critic_feedback}\n\n"
                "Please revise your plan based on this feedback."
            )
        else:
            phase_name = "KHÃM PHÃ" if is_exploration else "ÄÃ€O SÃ‚U"
            prompt_parts.append(
                f"\n\nHÃ£y táº¡o káº¿ hoáº¡ch phÃ¢n tÃ­ch cho giai Ä‘oáº¡n {phase_name}."
            )
        
        prompt = "\n".join(prompt_parts)
        
        # Call LLM
        response = await self.invoke_llm([HumanMessage(content=prompt)])
        
        # Parse response into structured output
        plan = self._parse_response(response.content, input_data)
        
        return PlannerOutput(
            plan=plan,
            reasoning=str(response.content),
            confidence=0.8,
        )
    
    def _format_exploration_summary(self, summary: dict[str, Any]) -> str:
        """Format exploration summary for deep dive prompt."""
        lines = []
        
        if "key_findings" in summary:
            lines.append("**PhÃ¡t hiá»‡n chÃ­nh:**")
            for finding in summary["key_findings"][:5]:
                lines.append(f"  â€¢ {finding}")
        
        if "data_overview" in summary:
            lines.append("\n**Sá»‘ liá»‡u tá»•ng quan:**")
            for key, value in summary["data_overview"].items():
                lines.append(f"  â€¢ {key}: {value}")
        
        if "trends" in summary:
            lines.append("\n**Xu hÆ°á»›ng:**")
            for trend in summary["trends"][:3]:
                lines.append(f"  â€¢ {trend}")
        
        if "notable_points" in summary:
            lines.append("\n**Äiá»ƒm Ä‘Ã¡ng chÃº Ã½:**")
            for point in summary["notable_points"][:3]:
                lines.append(f"  â€¢ {point}")
        
        return "\n".join(lines) if lines else "KhÃ´ng cÃ³ dá»¯ liá»‡u tá»« Phase 1"
    
    def _format_context(self, context: dict[str, Any]) -> str:
        """Format context for prompt with clear table listing."""
        parts = []
        
        # Schema description from Context Fusion (if available)
        if "schema_description" in context:
            parts.append(f"### Schema Context\n{context['schema_description'][:2000]}")
        
        if "tables" in context:
            parts.append("\n### ðŸ“‹ Available Tables (CHá»ˆ DÃ™NG NHá»®NG Báº¢NG NÃ€Y):")
            for table in context["tables"]:
                if isinstance(table, dict):
                    name = table.get('table_name', table.get('name', ''))
                    desc = table.get('description', '')[:80]
                    parts.append(f"  â€¢ {name}: {desc}" if desc else f"  â€¢ {name}")
                else:
                    parts.append(f"  â€¢ {table}")
        
        if "columns" in context:
            parts.append("\n### Relevant Columns")
            for col in context["columns"][:30]:  # Limit to avoid token overflow
                if isinstance(col, dict):
                    name = col.get('column_name', col.get('name', ''))
                    table = col.get('table_name', '')
                    desc = col.get('description', '')[:50]
                    parts.append(f"  â€¢ {table}.{name}: {desc}" if desc else f"  â€¢ {table}.{name}")
                else:
                    parts.append(f"  â€¢ {col}")
        
        if "metrics" in context:
            parts.append("\n### Business Metrics")
            for metric in context["metrics"]:
                parts.append(f"  â€¢ {metric}")
        
        if "joins" in context:
            parts.append("\n### Table Relationships")
            for join in context["joins"][:10]:  # Limit joins
                if isinstance(join, dict):
                    from_t = join.get('from_table', '')
                    to_t = join.get('to_table', '')
                    parts.append(f"  â€¢ {from_t} â†’ {to_t}")
                else:
                    parts.append(f"  â€¢ {join}")
        
        return "\n".join(parts) if parts else "No specific context available."
    
    def _format_plan(self, plan: AnalysisPlan) -> str:
        """Format existing plan for prompt."""
        lines = ["### Hypotheses"]
        for h in plan.hypotheses:
            lines.append(f"- [{h.status.value}] {h.statement}")
        
        lines.append("\n### Steps")
        for s in plan.steps:
            lines.append(f"{s.step_number}. [{s.action_type}] {s.description}")
        
        return "\n".join(lines)
    
    def _parse_response(
        self,
        response_content: str,
        input_data: PlannerInput,
    ) -> AnalysisPlan:
        """
        Parse LLM response into AnalysisPlan.
        
        Attempts to extract structured JSON from the response.
        Falls back to text parsing if JSON not found.
        """
        import json
        import re
        
        version = 1
        if input_data.previous_plan:
            version = input_data.previous_plan.version + 1
        
        hypotheses = []
        steps = []
        
        # Try to extract JSON from response
        try:
            # Look for JSON block in response
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response_content)
            if json_match:
                data = json.loads(json_match.group(1))
            else:
                # Try parsing entire response as JSON
                data = json.loads(response_content)
            
            # Parse hypotheses
            for i, h in enumerate(data.get("hypotheses", [])):
                hypotheses.append(Hypothesis(
                    id=h.get("id", f"h{i+1}"),
                    statement=h.get("statement", h.get("hypothesis", "")),
                    rationale=h.get("rationale", h.get("reason", "")),
                ))
            
            # Parse steps
            for i, s in enumerate(data.get("steps", [])):
                steps.append(AnalysisStep(
                    id=s.get("id", f"s{i+1}"),
                    hypothesis_id=s.get("hypothesis_id", ""),
                    description=s.get("description", ""),
                    action_type=s.get("action_type", s.get("actionType", "query")),
                    requirements=s.get("requirements", {}),
                    depends_on=s.get("depends_on", []),
                    step_number=s.get("step_number", s.get("stepNumber", i + 1)),
                    details=s.get("details", {}),
                    dependencies=s.get("dependencies", []),
                ))
                
        except (json.JSONDecodeError, KeyError):
            # Fall back to text parsing
            hypotheses, steps = self._parse_text_response(response_content)
        
        # Ensure at least one hypothesis and step
        if not hypotheses:
            hypotheses = [Hypothesis(
                id="h1",
                statement="PhÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘á»ƒ tÃ¬m nguyÃªn nhÃ¢n",
                rationale="Cáº§n kiá»ƒm tra dá»¯ liá»‡u trÆ°á»›c khi Ä‘Æ°a ra káº¿t luáº­n",
            )]
        
        if not steps:
            steps = [AnalysisStep(
                id="s1",
                hypothesis_id="h1",
                description="Truy váº¥n dá»¯ liá»‡u tá»•ng quan",
                action_type="query",
            )]
        
        return AnalysisPlan(
            question=input_data.question,
            hypotheses=hypotheses,
            steps=steps,
            context_used=input_data.enriched_context,
            version=version,
        )
    
    def _parse_text_response(
        self,
        response_content: str,
    ) -> tuple[list[Hypothesis], list[AnalysisStep]]:
        """Parse hypotheses and steps from unstructured text."""
        import re
        
        hypotheses = []
        steps = []
        
        lines = response_content.split("\n")
        current_section = None
        step_counter = 0
        hypothesis_counter = 0
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Detect section headers
            if any(kw in line.lower() for kw in ["hypothes", "giáº£ thuyáº¿t", "giáº£ thiáº¿t"]):
                current_section = "hypothesis"
                continue
            elif any(kw in line.lower() for kw in ["step", "bÆ°á»›c", "plan", "káº¿ hoáº¡ch"]):
                current_section = "step"
                continue
            
            # Parse hypotheses
            if current_section == "hypothesis":
                # Match numbered items like "1.", "H1:", "- ", etc.
                match = re.match(r'^(?:H?\d+[\.\):]?\s*|-\s*|â€¢\s*)(.+)$', line, re.IGNORECASE)
                if match:
                    hypothesis_counter += 1
                    hypotheses.append(Hypothesis(
                        id=f"h{hypothesis_counter}",
                        statement=match.group(1).strip(),
                        rationale="Extracted from plan",
                    ))
            
            # Parse steps
            elif current_section == "step":
                match = re.match(r'^(?:\d+[\.\):]?\s*|-\s*|â€¢\s*)(.+)$', line)
                if match:
                    step_counter += 1
                    desc = match.group(1).strip()
                    
                    # Detect action type
                    action_type = "query"
                    if any(kw in desc.lower() for kw in ["python", "pandas", "code"]):
                        action_type = "analysis"
                    elif any(kw in desc.lower() for kw in ["chart", "graph", "visual", "biá»ƒu Ä‘á»“"]):
                        action_type = "visualization"
                    
                    steps.append(AnalysisStep(
                        id=f"s{step_counter}",
                        hypothesis_id=f"h{hypothesis_counter}" if hypothesis_counter > 0 else "h1",
                        description=desc,
                        action_type=action_type,
                    ))
        
        return hypotheses, steps

